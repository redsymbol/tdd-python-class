= Test-Driven Development in Python 3
:author:    Aaron Maxwell <amax@redsymbol.net>
Copyright 2015 Aaron Maxwell.
:backend:   slidy
:source-highlighter: pygments

== Setup

Install Python 3.4 or later. (This very safely installs
alongside Python 2.)

Windows users need to do this too: http://goo.gl/m0cbM

== Hi, I'm Aaron

I'll teach you about test-driven development today. You can email me
at amax@redsymbol.net.

Also, I'm the author of a newsletter on advanced Python programming -
you can sign up and see the archives at http://migrateup.com/python/ .

== Automated Tests

The idea is to write programs that test our software. This is one of
the things that separates mediocre developers from world-class
engineers.

Types of automated test:

 * unit tests - What we'll focus on
 * integration tests - The next level up
 * end-to-end tests - Exercise complete sequences of functionality

== A Testable Function

Let's create a simple function.

[source,python]
----
>>> uniquewords("Hello hello, what a great day!")
5
----

Counts unique words, ignoring punctuation. A stub:

[source,python]
----
# in words.py
def uniquewords(text):
    pass
----

== Python's unittest module

Python includes not one, but *two* modules for writing automated tests:

 * `doctest` - Simple to learn and use. But takes you only so far.
 * `unittest` - An xUnit library. Lets you write any test you might need.

There are some popular third-party libs too:

 * `nose`
 * `pytest`
 
We'll focus on `unittest`.

== Basic Test

Here's a basic test for `uniquewords`:

[source,python]
----
import unittest
from words import uniquewords

class TestWords(unittest.TestCase):
    def test_uniquewords(self):
        self.assertEqual(2, uniquewords("foo bar FOO"))
----

== Running the test

On the command line:

////
python3 -m unittest test_words.py
////
[source,python]
[listing]
....
% python3 -m unittest test_words.py
F
======================================================================
FAIL: test_uniquewords (test_words.TestWords)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/amax/wdir/tdd-python-class/test_words.py", line 6, in test_uniquewords
    self.assertEqual(2, uniquewords("foo bar FOO"))
AssertionError: 2 != None

----------------------------------------------------------------------
Ran 1 test in 0.000s

FAILED (failures=1)
....

== The TDD Cycle

The steps for test-driven development look like this:

1. Create _stub(s)_ of the functions and/or classes - the minimum
needed.

1. Write a test.

1. Run that test. *See it fail.* Don't proceed until you see the failure.

1. Implement your functions and classes, and make the test pass.

1. Go to 1.

== Exercise

* Create a file named `words.py` containing `def uniquewords(text): pass`.

* Create a file named `test_words.py` with the following:

[source,python]
----
import unittest
from words import uniquewords
class TestWords(unittest.TestCase):
    def test_uniquewords(self):
        self.assertEqual(2, uniquewords("foo bar FOO"))
----

* Run the test with `python3 -m unittest test_words.py`. See it fail.

* Implement `uniquewords`. Run the test and make it pass.

== More Tests

Now add a few more tests:

[source,python]
----
class TestWords(unittest.TestCase):
    def test_uniquewords(self):
        self.assertEqual(2, uniquewords("foo bar FOO"))
	# NEW TESTS BELOW
        self.assertEqual(0, uniquewords(""))
        self.assertEqual(3, uniquewords("Truth is beauty; beauty, truth."))
        self.assertEqual(5, uniquewords("a b c d e a b c d e"))
----

Repeat the cycle:

1. Run the test, and see it fail.
1. Implement your code, and make the test pass.

== Let's Reflect

What did you discover?

Did all your new tests fail?

While editing `uniquewords`, did any previously passing tests break?

== Lots of Assertions

`unittest` gives you plenty of assertion methods:

* `assertEqual(a, b)`
* `assertTrue(x)`
* `assertFalse(x)`
* `assertIs(a, b)`
* `assertIsNone(x)`
* `assertIn(a, b)`
* `assertNotIn(a, b)`
* `assertIsInstance(a, b)`

Also "not" variants: `assertNotEqual`, etc.

== Using subtests

Here's a nifty Python-3-only feature. Look at our tests so far:

[source,python]
----
    def test_uniquewords(self):
        self.assertEqual(2, uniquewords("foo bar FOO"))
        self.assertEqual(0, uniquewords(""))
        self.assertEqual(3, uniquewords("Truth is beauty; beauty, truth."))
        self.assertEqual(5, uniquewords("a b c d e a b c d e"))
----

It's a little repetitive, isn't it? Not horrible, but if our code is
more complex, and we have a few dozen assertions, the boilerplate will
start to stack up.

== And another problem...

Suppose my sneaky coworker sabotages my code:

[source,python]
----
def uniquewords(text):
    return -1
----

When I run the test, I just the first assertion failing - even though all four
should have failed:

[listing]
....
Traceback (most recent call last):
  File "/Users/amax/wdir/tdd-python-class/test_words.py", line 6, in test_uniquewords
    self.assertEqual(2, uniquewords("foo bar FOO"))
AssertionError: 2 != -1
....

== What would be better?

In general, when a test fails, it helps to know about _all_ the
failures, not just the first one.

Python 3 introduces a feature called `subtests` that solves all these
problems beautifully.

== Using Subtests

[source,python]
----
    def test_uniquewords(self):
        testdata = [
            (0, ""),
            (2, "foo bar FOO"),
            (3, "Truth is beauty; beauty, truth."),
            (5, "a b c d e a b c d e"),
            ]
        for count, text in testdata:
            with self.subTest(count=count, text=text):
                self.assertEqual(count, uniquewords(text))
----

Now when I run the tests, EVERY failed assertion is presented!

== Exercise

1. In your `test_words.py`, rename your previous `test_uniquewords` to be
`_test_uniquewords`, and create a new `def
test_uniquewords(self)`. This way you can keep your old code as a
reference.

1. Sabotage your `uniquewords` function just like my coworker did
(i.e. `return -1`). Populate your new `test_uniquewords` with the same
tests as a before, only using subtests this time. Run the test, and
see it fail.

1. Un-sabotage `uniquewords`, run the tests, and see them pass.

1. Now add three new tests to `test_uniquewords`. Come up with your
own test inputs. Make at least one break your code. Then fix it!

== Testing Assertions

Let's say we decide it's an error to pass in an empty string.  We
decide that `uniquewords` should raise a `ValueError` when called this
way. How can we build a test for this?

== assertRaises

We can use the `assertRaises` method of `TestCase`.

[source,python]
----
    def test_uniquewords_badinput(self):
        with self.assertRaises(ValueError):
            uniquewords("")
----

== assertRaises

Then we get the following:

[listing]
....
python3 -m unittest test_words.py
.F
======================================================================
FAIL: test_uniquewords_badinput (test_words.TestWords)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/amax/wdir/tdd-python-class/test_words.py", line 11, in test_uniquewords_badinput
    uniquewords("")
AssertionError: ValueError not raised
....

Great! Now we write can implement the correct logic, and make the test
pass.

== Checking the exception

We can check the argument to `ValueError` by passing it through
`str()`:

[source,python]
----
>>> ve = ValueError("booga booga")
>>> str(ve)
'booga booga'
----

`assertRaises` gives us the exception object if we ask for it:

[source,python]
----
    def test_uniquewords_badinput(self):
        with self.assertRaises(ValueError) as context:
            uniquewords("")
        ve = context.exception
        self.assertEqual("Input must have at least one word", str(ve))
----

== Exercise assertRaises

In `test_uniquewords_badinput`, do the following.

1. Create a test that verifies `ValueError` is raised if the input
does not contain at least one word. Run the test and see it fail.

1. Modify `uniquewords` so all tests pass.

1. Add new tests so that `ValueError` is raised if `None` or an
integer are passed in, instead of a string. Run the test and see it
fail.

1. Make all tests pass again.
